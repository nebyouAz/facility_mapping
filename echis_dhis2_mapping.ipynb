{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import recordlinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify path directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify root folder\n",
    "root_folder = r'Development\\facility_mapping_old'\n",
    "\n",
    "# Combined Excel file\n",
    "new_excel_file_path = root_folder + r'\\Data\\master_file_new.xlsx'\n",
    "\n",
    "# Zone file\n",
    "zone_mappings_file_path = root_folder + r'\\Output\\zone_mappings.xlsx'\n",
    "\n",
    "# Woreda file\n",
    "woreda_mappings_file_path = root_folder + r'\\Output\\woreda_mappings.xlsx'\n",
    "\n",
    "# HP mapping path\n",
    "hp_mappings_file_path = root_folder + r'\\Output\\hp_final_mappings.xlsx'\n",
    "\n",
    "# HP mapping path\n",
    "hc_mappings_file_path = root_folder + '\\Output\\hc_final_mappings.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data and rename columns where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_eCHIS_combined = pd.read_excel(new_excel_file_path, sheet_name='echis_master')\n",
    "df_new_eCHIS_combined = df_new_eCHIS_combined.add_suffix('_echis')\n",
    "\n",
    "df_dhis2 = pd.read_excel(new_excel_file_path, sheet_name='dhis2_master')\n",
    "df_dhis2.rename(columns={'Region':'region_name_dhis2', 'Zone':'zone_name_dhis2', 'Woreda':'woreda_name_dhis2', 'PHCU':'hc_name_dhis2', 'Facility Name':'facility_name_dhis2'}, inplace=True)\n",
    "\n",
    "print('# of records in DHIS2:\\t\\t', len(df_dhis2))\n",
    "\n",
    "print('# of records in mfr:\\t\\t', len(df_new_eCHIS_combined))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make adjustments for Dire Dawa\n",
    "df_new_eCHIS_combined['zone_name_echis'] = df_new_eCHIS_combined[['woreda_name_echis','zone_name_echis','region_name_echis']].apply(lambda x : x.woreda_name_echis if x.region_name_echis == 'Dire Dawa' else x.zone_name_echis, axis=1)\n",
    "\n",
    "print('# of potential health posts in mfr', len(df_new_eCHIS_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using recordlinkage to link dhis2 and echis regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_e = df_new_eCHIS_combined[['region_name_echis']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "region_d = df_dhis2[['region_name_dhis2']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "\n",
    "print(region_e)\n",
    "print(region_d)\n",
    "\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.full()\n",
    "region_candidate_links = indexer.index(region_e, region_d)\n",
    "\n",
    "compare_cl = recordlinkage.Compare()\n",
    "compare_cl.string('region_name_echis', 'region_name_dhis2', method='jarowinkler', label='match_score')\n",
    "\n",
    "regions_linked = compare_cl.compute(region_candidate_links, region_e, region_d)\n",
    "regions_linked = regions_linked.reset_index()\n",
    "\n",
    "regions_linked = regions_linked.merge(region_e.reset_index().rename({'index':'level_0'},axis=1), how='left', on='level_0')\n",
    "\n",
    "regions_linked = regions_linked.merge(region_d.reset_index().rename({'index':'level_1'},axis=1), how='left', on='level_1')\n",
    "\n",
    "regions_linked['ranked'] = regions_linked.groupby('level_0')['match_score'].rank(ascending=False)\n",
    "\n",
    "regions_linked = regions_linked[regions_linked['ranked'] == 1]\n",
    "\n",
    "# Add the mapped regions to the eCHIS dataframe\n",
    "df_new_eCHIS_combined_with_mappings = df_new_eCHIS_combined.merge(regions_linked[['region_name_echis','region_name_dhis2']], how='left', left_on='region_name_echis', right_on='region_name_echis')\n",
    "\n",
    "df_new_eCHIS_combined_with_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using recordlinkage to link zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_e = df_eCHIS_combined_with_mappings[['region_name_mfr', 'zone_name_echis']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "zone_m = df_mfr_updated[['region_name_mfr', 'zone_name_mfr']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block('region_name_mfr')\n",
    "zone_candidate_links = indexer.index(zone_e, zone_m)\n",
    "\n",
    "compare_cl = recordlinkage.Compare()\n",
    "compare_cl.string('zone_name_echis', 'zone_name_mfr', method='jarowinkler', label='match_score') \n",
    "\n",
    "zones_linked = compare_cl.compute(zone_candidate_links, zone_e, zone_m) \n",
    "zones_linked = zones_linked.reset_index()\n",
    "zones_linked = zones_linked.merge(zone_e.reset_index().rename({'index':'level_0'},axis=1), how='left', on='level_0')\n",
    "zones_linked = zones_linked.merge(zone_m[['zone_name_mfr']].reset_index().rename({'index':'level_1'},axis=1), how='left', on='level_1')\n",
    "zones_linked['ranked'] = zones_linked.groupby('level_0')['match_score'].rank(ascending=False, method='first')\n",
    "zones_linked['confirmation_required'] = zones_linked[['ranked', 'match_score']].apply(lambda x : 1 if ((x.match_score >= 0.8) and (x.ranked == 1)) else None, axis=1)\n",
    "\n",
    "# For zones where it is ranked as 1, but score is below 0.8, create a list of those (which will be manually checked)\n",
    "zones_manual = zones_linked[(zones_linked['ranked'] == 1) & (zones_linked['confirmation_required'].isnull())]['level_0'].unique()\n",
    "\n",
    "# Check if a zone from mfr is mapped to more than one from echis\n",
    "zones_duplicate_matches = zones_linked[zones_linked['confirmation_required'] == 1].groupby('level_1').agg({'level_0':'nunique'}).reset_index()\n",
    "zones_duplicate_matches = zones_duplicate_matches[zones_duplicate_matches['level_0'] > 1]['level_1']\n",
    "\n",
    "zones_linked['duplicate_mfr_match'] = zones_linked[['confirmation_required','level_1']].apply(lambda x : 1 if ((x.confirmation_required == 1) and (x.level_1 in list(zones_duplicate_matches))) else None, axis=1)\n",
    "zones_linked['manual_intervention'] = zones_linked['level_0'].apply(lambda x : 0 if x in zones_manual else None)\n",
    "\n",
    "try:\n",
    "    zones_linked = pd.read_excel(zone_mappings_file_path)\n",
    "except:\n",
    "    zones_linked.to_excel(zone_mappings_file_path, index=False)\n",
    "\n",
    "# Manual intervention will be required at this stage to ensure zones are mapped correctly\n",
    "\n",
    "print('Unique Zones: ', len(zones_linked[['level_0']].drop_duplicates()))\n",
    "zones_linked = zones_linked[(zones_linked['confirmation_required'] == 1) | (zones_linked['manual_intervention'] == 1)]\n",
    "print('Zones mapped: ', len(zones_linked))\n",
    "\n",
    "df_eCHIS_combined_with_mappings = df_eCHIS_combined_with_mappings.merge(zones_linked[['region_name_mfr','zone_name_echis','zone_name_mfr']], how='left', left_on=['zone_name_echis','region_name_mfr'], right_on=['zone_name_echis','region_name_mfr'])\n",
    "zones_linked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using recordlinkage to link woredas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woreda_e = df_eCHIS_combined_with_mappings[['region_name_mfr', 'zone_name_mfr', 'woreda_name_echis']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "woreda_m = df_mfr_updated[['region_name_mfr', 'zone_name_mfr', 'woreda_name_mfr']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block(['region_name_mfr', 'zone_name_mfr'], ['region_name_mfr', 'zone_name_mfr'])\n",
    "woreda_candidate_links = indexer.index(woreda_e, woreda_m)\n",
    "\n",
    "compare_cl = recordlinkage.Compare()\n",
    "compare_cl.string('woreda_name_echis', 'woreda_name_mfr', method='jarowinkler', label='match_score')\n",
    "\n",
    "woredas_linked = compare_cl.compute(woreda_candidate_links, woreda_e, woreda_m)\n",
    "woredas_linked = woredas_linked.reset_index()\n",
    "woredas_linked = woredas_linked.merge(woreda_e.reset_index().rename({'index':'level_0'},axis=1), how='left', on='level_0')\n",
    "woredas_linked = woredas_linked.merge(woreda_m[['woreda_name_mfr']].reset_index().rename({'index':'level_1'},axis=1), how='left', on='level_1')\n",
    "woredas_linked['ranked'] = woredas_linked.groupby('level_0')['match_score'].rank(ascending=False, method='first')\n",
    "woredas_linked['confirmation_required'] = woredas_linked[['ranked', 'match_score']].apply(lambda x : 1 if ((x.match_score >= 0.8) and (x.ranked == 1)) else None, axis=1)\n",
    "\n",
    "# For woredas where it is ranked as 1, but score is below 0.8, create a list of those (which will be manually checked)\n",
    "woredas_manual = woredas_linked[(woredas_linked['ranked'] == 1) & (woredas_linked['confirmation_required'].isnull())]['level_0'].unique()\n",
    "\n",
    "# Check if a woreda from mfr is mapped to more than one from echis\n",
    "woreda_duplicate_matches = woredas_linked[woredas_linked['confirmation_required'] == 1].groupby('level_1').agg({'level_0':'nunique'}).reset_index()\n",
    "woreda_duplicate_matches = woreda_duplicate_matches[woreda_duplicate_matches['level_0'] > 1]['level_1']\n",
    "\n",
    "woredas_linked['duplicate_mfr_match'] = woredas_linked[['confirmation_required','level_1']].apply(lambda x : 1 if ((x.confirmation_required == 1) and (x.level_1 in list(woreda_duplicate_matches))) else None, axis=1)\n",
    "woredas_linked['manual_intervention'] = woredas_linked['level_0'].apply(lambda x : 0 if x in woredas_manual else None)\n",
    "\n",
    "try:\n",
    "    woredas_linked = pd.read_excel(woreda_mappings_file_path)\n",
    "except:\n",
    "    woredas_linked.to_excel(woreda_mappings_file_path, index=False)\n",
    "\n",
    "# Manual intervention will be required at this stage to ensure woredas are mapped correctly\n",
    "\n",
    "print('Unique Woredas: ', len(woredas_linked[['level_0']].drop_duplicates()))\n",
    "woredas_linked = woredas_linked[(woredas_linked['confirmation_required'] == 1) | (woredas_linked['manual_intervention'] == 1)]\n",
    "print('Woredas mapped: ', len(woredas_linked))\n",
    "\n",
    "df_eCHIS_combined_with_mappings = df_eCHIS_combined_with_mappings.merge(woredas_linked[['region_name_mfr','zone_name_mfr','woreda_name_echis','woreda_name_mfr']], how='left', left_on=['woreda_name_echis', 'zone_name_mfr','region_name_mfr'], right_on=['woreda_name_echis', 'zone_name_mfr','region_name_mfr'])\n",
    "woredas_linked "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facility_mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1f3241e30d2706c5b66311aa22039891fcdb27f0cae8dc9436da2122278e84d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
